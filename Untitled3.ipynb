{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from parameters import *\n",
    "import sys\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = ALPHA):\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist, neg_dist), alpha)\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model found\n",
      "Loading custom trained model...\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "if(os.path.exists('models/facenet_keras.h5')):\n",
    "    print(\"Trained model found\")\n",
    "    print(\"Loading custom trained model...\")\n",
    "    FRmodel = keras.models.load_model('models/facenet_keras.h5', custom_objects={'triplet_loss': triplet_loss})        \n",
    "    print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database, model):\n",
    "    \n",
    "    encoding = img_to_encoding2(image_path, model, False)\n",
    "    min_dist = 1000\n",
    "    for  pic in database:\n",
    "        dist = np.linalg.norm(encoding - pic)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "    print(identity + ' : ' +str(min_dist)+ ' ' + str(len(database)))\n",
    "    \n",
    "    if min_dist<THRESHOLD:\n",
    "        door_open = True\n",
    "    else:\n",
    "        door_open = False\n",
    "        \n",
    "    return min_dist, door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding2(image_path, model, path=True):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = tf.keras.applications.inception_resnet_v2.preprocess_input(img)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_encoder = Normalizer(norm='l2')\n",
    "out_encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = []\n",
    "trainy = []\n",
    "for name in faces:\n",
    "    ben_list = os.listdir('cropped/' + name)\n",
    "\n",
    "    for i in ben_list:\n",
    "        trainx.append(img_to_encoding2('cropped/' + name + '/' + i, FRmodel)[0])\n",
    "        trainy.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx = []\n",
    "testy = []\n",
    "for name in faces:\n",
    "    ben_list = os.listdir('val_set/' + name)\n",
    "\n",
    "    for i in ben_list:\n",
    "        testx.append(img_to_encoding2('val_set/' + name + '/' + i, FRmodel)[0])\n",
    "        testy.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = in_encoder.transform(trainx)\n",
    "testX = in_encoder.transform(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(trainx, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90186194, 0.02073325, 0.04025225, 0.01700607, 0.02014649],\n",
       "       [0.50218802, 0.15672076, 0.0903334 , 0.09133339, 0.15942443],\n",
       "       [0.86597527, 0.04029886, 0.06061351, 0.01388327, 0.01922909],\n",
       "       [0.83169513, 0.03596328, 0.05511404, 0.03022473, 0.04700282],\n",
       "       [0.85406447, 0.06368105, 0.0217547 , 0.02756038, 0.0329394 ],\n",
       "       [0.07255696, 0.67741186, 0.02013622, 0.04859096, 0.18130401],\n",
       "       [0.15009353, 0.12756832, 0.06400173, 0.24521329, 0.41312313],\n",
       "       [0.01187035, 0.90914979, 0.01278199, 0.04886923, 0.01732865],\n",
       "       [0.0013974 , 0.9776589 , 0.00541807, 0.00378019, 0.01174544],\n",
       "       [0.02790266, 0.07372731, 0.85030182, 0.02819157, 0.01987664],\n",
       "       [0.01372556, 0.06005216, 0.86977596, 0.03289656, 0.02354977],\n",
       "       [0.01003571, 0.0433521 , 0.91093123, 0.02205556, 0.0136254 ],\n",
       "       [0.05307383, 0.04196688, 0.86375683, 0.02643373, 0.01476872],\n",
       "       [0.01276072, 0.05693424, 0.857704  , 0.04613053, 0.02647052],\n",
       "       [0.02796611, 0.24987225, 0.02072082, 0.65940572, 0.04203509],\n",
       "       [0.00805543, 0.02375564, 0.00621091, 0.95601474, 0.00596327],\n",
       "       [0.06945326, 0.11356281, 0.03282779, 0.76984003, 0.01431611],\n",
       "       [0.0247583 , 0.03960059, 0.01661205, 0.90308594, 0.01594311],\n",
       "       [0.02855782, 0.02789921, 0.01944605, 0.88972092, 0.034376  ],\n",
       "       [0.02883237, 0.07535672, 0.02115274, 0.06654646, 0.80811171],\n",
       "       [0.03029777, 0.06718469, 0.01291446, 0.06202669, 0.82757639],\n",
       "       [0.02979601, 0.04993598, 0.0146519 , 0.08966579, 0.81595032],\n",
       "       [0.03322755, 0.17364698, 0.09576528, 0.07889474, 0.61846545],\n",
       "       [0.01950988, 0.07340682, 0.04310381, 0.03842202, 0.82555748]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_test = model.predict_proba(testx)\n",
    "yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ben_afflek', 'ben_afflek')\n",
      "('ben_afflek', 'ben_afflek')\n",
      "('ben_afflek', 'ben_afflek')\n",
      "('ben_afflek', 'ben_afflek')\n",
      "('ben_afflek', 'ben_afflek')\n",
      "('ben_afflek', 'elton_john')\n",
      "('ben_afflek', 'elton_john')\n",
      "('ben_afflek', 'elton_john')\n",
      "('ben_afflek', 'elton_john')\n",
      "('ben_afflek', 'jerry_seinfeld')\n",
      "('ben_afflek', 'jerry_seinfeld')\n",
      "('ben_afflek', 'jerry_seinfeld')\n",
      "('ben_afflek', 'jerry_seinfeld')\n",
      "('ben_afflek', 'jerry_seinfeld')\n",
      "('elton_john', 'madonna')\n",
      "('elton_john', 'madonna')\n",
      "('elton_john', 'madonna')\n",
      "('elton_john', 'madonna')\n",
      "('elton_john', 'madonna')\n",
      "('elton_john', 'mindy_kaling')\n",
      "('elton_john', 'mindy_kaling')\n",
      "('elton_john', 'mindy_kaling')\n",
      "('elton_john', 'mindy_kaling')\n",
      "('elton_john', 'mindy_kaling')\n"
     ]
    }
   ],
   "source": [
    "for i in zip(trainy, testy):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = model.predict(testx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_test = accuracy_score(testy, yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: test=95.833\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: test=%.3f' % (score_test*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
