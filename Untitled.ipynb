{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size [112, 112]\n",
      "model number 1\n",
      "loading ./models/model 0\n",
      "model loading time 0.354002\n",
      "\n",
      "agedb_30\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Helper for evaluation on the Labeled Faces in the Wild dataset \n",
    "\"\"\"\n",
    "\n",
    "# MIT License\n",
    "# \n",
    "# Copyright (c) 2016 David Sandberg\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "# \n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import interpolate\n",
    "import sklearn\n",
    "import cv2\n",
    "import math\n",
    "import datetime\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "import mxnet as mx\n",
    "from mxnet import ndarray as nd\n",
    "\n",
    "\n",
    "class LFold:\n",
    "  def __init__(self, n_splits = 2, shuffle = False):\n",
    "    self.n_splits = n_splits\n",
    "    if self.n_splits>1:\n",
    "      self.k_fold = KFold(n_splits = n_splits, shuffle = shuffle)\n",
    "\n",
    "  def split(self, indices):\n",
    "    if self.n_splits>1:\n",
    "      return self.k_fold.split(indices)\n",
    "    else:\n",
    "      return [(indices, indices)]\n",
    "\n",
    "\n",
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10, pca = 0):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = LFold(n_splits=nrof_folds, shuffle=False)\n",
    "    \n",
    "    tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "    accuracy = np.zeros((nrof_folds))\n",
    "    indices = np.arange(nrof_pairs)\n",
    "    #print('pca', pca)\n",
    "    \n",
    "    if pca==0:\n",
    "      diff = np.subtract(embeddings1, embeddings2)\n",
    "      dist = np.sum(np.square(diff),1)\n",
    "    \n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "        #print('train_set', train_set)\n",
    "        #print('test_set', test_set)\n",
    "        if pca>0:\n",
    "          print('doing pca on', fold_idx)\n",
    "          embed1_train = embeddings1[train_set]\n",
    "          embed2_train = embeddings2[train_set]\n",
    "          _embed_train = np.concatenate( (embed1_train, embed2_train), axis=0 )\n",
    "          #print(_embed_train.shape)\n",
    "          pca_model = PCA(n_components=pca)\n",
    "          pca_model.fit(_embed_train)\n",
    "          embed1 = pca_model.transform(embeddings1)\n",
    "          embed2 = pca_model.transform(embeddings2)\n",
    "          embed1 = sklearn.preprocessing.normalize(embed1)\n",
    "          embed2 = sklearn.preprocessing.normalize(embed2)\n",
    "          #print(embed1.shape, embed2.shape)\n",
    "          diff = np.subtract(embed1, embed2)\n",
    "          dist = np.sum(np.square(diff),1)\n",
    "        \n",
    "        # Find the best threshold for the fold\n",
    "        acc_train = np.zeros((nrof_thresholds))\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
    "        best_threshold_index = np.argmax(acc_train)\n",
    "        #print('threshold', thresholds[best_threshold_index])\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
    "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
    "          \n",
    "    tpr = np.mean(tprs,0)\n",
    "    fpr = np.mean(fprs,0)\n",
    "    return tpr, fpr, accuracy\n",
    "\n",
    "def calculate_accuracy(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
    "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
    "  \n",
    "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n",
    "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n",
    "    acc = float(tp+tn)/dist.size\n",
    "    return tpr, fpr, acc\n",
    "\n",
    "\n",
    "  \n",
    "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10):\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "    nrof_thresholds = len(thresholds)\n",
    "    k_fold = LFold(n_splits=nrof_folds, shuffle=False)\n",
    "    \n",
    "    val = np.zeros(nrof_folds)\n",
    "    far = np.zeros(nrof_folds)\n",
    "    \n",
    "    diff = np.subtract(embeddings1, embeddings2)\n",
    "    dist = np.sum(np.square(diff),1)\n",
    "    indices = np.arange(nrof_pairs)\n",
    "    \n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "      \n",
    "        # Find the threshold that gives FAR = far_target\n",
    "        far_train = np.zeros(nrof_thresholds)\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\n",
    "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n",
    "        if np.max(far_train)>=far_target:\n",
    "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
    "            threshold = f(far_target)\n",
    "        else:\n",
    "            threshold = 0.0\n",
    "    \n",
    "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n",
    "  \n",
    "    val_mean = np.mean(val)\n",
    "    far_mean = np.mean(far)\n",
    "    val_std = np.std(val)\n",
    "    return val_mean, val_std, far_mean\n",
    "\n",
    "\n",
    "def calculate_val_far(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    n_same = np.sum(actual_issame)\n",
    "    n_diff = np.sum(np.logical_not(actual_issame))\n",
    "    #print(true_accept, false_accept)\n",
    "    #print(n_same, n_diff)\n",
    "    val = float(true_accept) / float(n_same)\n",
    "    far = float(false_accept) / float(n_diff)\n",
    "    return val, far\n",
    "\n",
    "def evaluate(embeddings, actual_issame, nrof_folds=10, pca = 0):\n",
    "    # Calculate evaluation metrics\n",
    "    thresholds = np.arange(0, 4, 0.01)\n",
    "    embeddings1 = embeddings[0::2]\n",
    "    embeddings2 = embeddings[1::2]\n",
    "    tpr, fpr, accuracy = calculate_roc(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), nrof_folds=nrof_folds, pca = pca)\n",
    "    thresholds = np.arange(0, 4, 0.001)\n",
    "    val, val_std, far = calculate_val(thresholds, embeddings1, embeddings2,\n",
    "        np.asarray(actual_issame), 1e-3, nrof_folds=nrof_folds)\n",
    "    return tpr, fpr, accuracy, val, val_std, far\n",
    "\n",
    "def load_bin(path, image_size):\n",
    "  try:\n",
    "    with open(path, 'rb') as f:\n",
    "      bins, issame_list = pickle.load(f) #py2\n",
    "  except UnicodeDecodeError as e:\n",
    "    with open(path, 'rb') as f:\n",
    "      bins, issame_list = pickle.load(f, encoding='bytes') #py3\n",
    "  data_list = []\n",
    "  for flip in [0,1]:\n",
    "    data = nd.empty((len(issame_list)*2, 3, image_size[0], image_size[1]))\n",
    "    data_list.append(data)\n",
    "  for i in range(len(issame_list)*2):\n",
    "    _bin = bins[i]\n",
    "    img = mx.image.imdecode(_bin)\n",
    "    if img.shape[1]!=image_size[0]:\n",
    "      img = mx.image.resize_short(img, image_size[0])\n",
    "    img = nd.transpose(img, axes=(2, 0, 1))\n",
    "    for flip in [0,1]:\n",
    "      if flip==1:\n",
    "        img = mx.ndarray.flip(data=img, axis=2)\n",
    "      data_list[flip][i][:] = img\n",
    "    if i%1000==0:\n",
    "      print('loading bin', i)\n",
    "  print(data_list[0].shape)\n",
    "  return (data_list, issame_list)\n",
    "\n",
    "def test(data_set, mx_model, batch_size, nfolds=10, data_extra = None, label_shape = None):\n",
    "  print('testing verification..')\n",
    "  data_list = data_set[0]\n",
    "  issame_list = data_set[1]\n",
    "  model = mx_model\n",
    "  embeddings_list = []\n",
    "  if data_extra is not None:\n",
    "    _data_extra = nd.array(data_extra)\n",
    "  time_consumed = 0.0\n",
    "  if label_shape is None:\n",
    "    _label = nd.ones( (batch_size,) )\n",
    "  else:\n",
    "    _label = nd.ones( label_shape )\n",
    "  for i in range( len(data_list) ):\n",
    "    data = data_list[i]\n",
    "    embeddings = None\n",
    "    ba = 0\n",
    "    while ba<data.shape[0]:\n",
    "      bb = min(ba+batch_size, data.shape[0])\n",
    "      count = bb-ba\n",
    "      _data = nd.slice_axis(data, axis=0, begin=bb-batch_size, end=bb)\n",
    "      #print(_data.shape, _label.shape)\n",
    "      time0 = datetime.datetime.now()\n",
    "      if data_extra is None:\n",
    "        db = mx.io.DataBatch(data=(_data,), label=(_label,))\n",
    "      else:\n",
    "        db = mx.io.DataBatch(data=(_data,_data_extra), label=(_label,))\n",
    "      model.forward(db, is_train=False)\n",
    "      net_out = model.get_outputs()\n",
    "      #_arg, _aux = model.get_params()\n",
    "      #__arg = {}\n",
    "      #for k,v in _arg.iteritems():\n",
    "      #  __arg[k] = v.as_in_context(_ctx)\n",
    "      #_arg = __arg\n",
    "      #_arg[\"data\"] = _data.as_in_context(_ctx)\n",
    "      #_arg[\"softmax_label\"] = _label.as_in_context(_ctx)\n",
    "      #for k,v in _arg.iteritems():\n",
    "      #  print(k,v.context)\n",
    "      #exe = sym.bind(_ctx, _arg ,args_grad=None, grad_req=\"null\", aux_states=_aux)\n",
    "      #exe.forward(is_train=False)\n",
    "      #net_out = exe.outputs\n",
    "      _embeddings = net_out[0].asnumpy()\n",
    "      time_now = datetime.datetime.now()\n",
    "      diff = time_now - time0\n",
    "      time_consumed+=diff.total_seconds()\n",
    "      #print(_embeddings.shape)\n",
    "      if embeddings is None:\n",
    "        embeddings = np.zeros( (data.shape[0], _embeddings.shape[1]) )\n",
    "      embeddings[ba:bb,:] = _embeddings[(batch_size-count):,:]\n",
    "      ba = bb\n",
    "    embeddings_list.append(embeddings)\n",
    "\n",
    "  _xnorm = 0.0\n",
    "  _xnorm_cnt = 0\n",
    "  for embed in embeddings_list:\n",
    "    for i in range(embed.shape[0]):\n",
    "      _em = embed[i]\n",
    "      _norm=np.linalg.norm(_em)\n",
    "      #print(_em.shape, _norm)\n",
    "      _xnorm+=_norm\n",
    "      _xnorm_cnt+=1\n",
    "  _xnorm /= _xnorm_cnt\n",
    "\n",
    "  embeddings = embeddings_list[0].copy()\n",
    "  embeddings = sklearn.preprocessing.normalize(embeddings)\n",
    "  acc1 = 0.0\n",
    "  std1 = 0.0\n",
    "  #_, _, accuracy, val, val_std, far = evaluate(embeddings, issame_list, nrof_folds=10)\n",
    "  #acc1, std1 = np.mean(accuracy), np.std(accuracy)\n",
    "\n",
    "  #print('Validation rate: %2.5f+-%2.5f @ FAR=%2.5f' % (val, val_std, far))\n",
    "  #embeddings = np.concatenate(embeddings_list, axis=1)\n",
    "  embeddings = embeddings_list[0] + embeddings_list[1]\n",
    "  embeddings = sklearn.preprocessing.normalize(embeddings)\n",
    "  print(embeddings.shape)\n",
    "  print('infer time', time_consumed)\n",
    "  _, _, accuracy, val, val_std, far = evaluate(embeddings, issame_list, nrof_folds=nfolds)\n",
    "  acc2, std2 = np.mean(accuracy), np.std(accuracy)\n",
    "  return acc1, std1, acc2, std2, _xnorm, embeddings_list\n",
    "\n",
    "def test_badcase(data_set, mx_model, batch_size, name='', data_extra = None, label_shape = None):\n",
    "  print('testing verification badcase..')\n",
    "  data_list = data_set[0]\n",
    "  issame_list = data_set[1]\n",
    "  model = mx_model\n",
    "  embeddings_list = []\n",
    "  if data_extra is not None:\n",
    "    _data_extra = nd.array(data_extra)\n",
    "  time_consumed = 0.0\n",
    "  if label_shape is None:\n",
    "    _label = nd.ones( (batch_size,) )\n",
    "  else:\n",
    "    _label = nd.ones( label_shape )\n",
    "  for i in range( len(data_list) ):\n",
    "    data = data_list[i]\n",
    "    embeddings = None\n",
    "    ba = 0\n",
    "    while ba<data.shape[0]:\n",
    "      bb = min(ba+batch_size, data.shape[0])\n",
    "      count = bb-ba\n",
    "      _data = nd.slice_axis(data, axis=0, begin=bb-batch_size, end=bb)\n",
    "      #print(_data.shape, _label.shape)\n",
    "      time0 = datetime.datetime.now()\n",
    "      if data_extra is None:\n",
    "        db = mx.io.DataBatch(data=(_data,), label=(_label,))\n",
    "      else:\n",
    "        db = mx.io.DataBatch(data=(_data,_data_extra), label=(_label,))\n",
    "      model.forward(db, is_train=False)\n",
    "      net_out = model.get_outputs()\n",
    "      _embeddings = net_out[0].asnumpy()\n",
    "      time_now = datetime.datetime.now()\n",
    "      diff = time_now - time0\n",
    "      time_consumed+=diff.total_seconds()\n",
    "      if embeddings is None:\n",
    "        embeddings = np.zeros( (data.shape[0], _embeddings.shape[1]) )\n",
    "      embeddings[ba:bb,:] = _embeddings[(batch_size-count):,:]\n",
    "      ba = bb\n",
    "    embeddings_list.append(embeddings)\n",
    "  embeddings = embeddings_list[0] + embeddings_list[1]\n",
    "  embeddings = sklearn.preprocessing.normalize(embeddings)\n",
    "  thresholds = np.arange(0, 4, 0.01)\n",
    "  actual_issame = np.asarray(issame_list)\n",
    "  nrof_folds = 10\n",
    "  embeddings1 = embeddings[0::2]\n",
    "  embeddings2 = embeddings[1::2]\n",
    "  assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
    "  assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
    "  nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
    "  nrof_thresholds = len(thresholds)\n",
    "  k_fold = LFold(n_splits=nrof_folds, shuffle=False)\n",
    "  \n",
    "  tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "  fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
    "  accuracy = np.zeros((nrof_folds))\n",
    "  indices = np.arange(nrof_pairs)\n",
    "  \n",
    "  diff = np.subtract(embeddings1, embeddings2)\n",
    "  dist = np.sum(np.square(diff),1)\n",
    "  data = data_list[0]\n",
    "\n",
    "  pouts = []\n",
    "  nouts = []\n",
    "  \n",
    "  for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
    "       \n",
    "      # Find the best threshold for the fold\n",
    "      acc_train = np.zeros((nrof_thresholds))\n",
    "      #print(train_set)\n",
    "      #print(train_set.__class__)\n",
    "      for threshold_idx, threshold in enumerate(thresholds):\n",
    "          p2 = dist[train_set]\n",
    "          p3 = actual_issame[train_set]\n",
    "          _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, p2, p3)\n",
    "      best_threshold_index = np.argmax(acc_train)\n",
    "      for threshold_idx, threshold in enumerate(thresholds):\n",
    "          tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
    "      _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
    "      best_threshold = thresholds[best_threshold_index]\n",
    "      for iid in test_set:\n",
    "        ida = iid*2\n",
    "        idb = ida+1\n",
    "        asame = actual_issame[iid]\n",
    "        _dist = dist[iid]\n",
    "        violate = _dist - best_threshold\n",
    "        if not asame:\n",
    "          violate *= -1.0\n",
    "        if violate>0.0:\n",
    "          imga = data[ida].asnumpy().transpose( (1,2,0) )[...,::-1] #to bgr\n",
    "          imgb = data[idb].asnumpy().transpose( (1,2,0) )[...,::-1]\n",
    "          #print(imga.shape, imgb.shape, violate, asame, _dist)\n",
    "          if asame:\n",
    "            pouts.append( (imga, imgb, _dist, best_threshold, ida) )\n",
    "          else:\n",
    "            nouts.append( (imga, imgb, _dist, best_threshold, ida) )\n",
    "\n",
    "        \n",
    "  tpr = np.mean(tprs,0)\n",
    "  fpr = np.mean(fprs,0)\n",
    "  acc = np.mean(accuracy)\n",
    "  pouts = sorted(pouts, key = lambda x: x[2], reverse=True)\n",
    "  nouts = sorted(nouts, key = lambda x: x[2], reverse=False)\n",
    "  print(len(pouts), len(nouts))\n",
    "  print('acc', acc)\n",
    "  gap = 10\n",
    "  image_shape = (112,224,3)\n",
    "  out_dir = \"./badcases\"\n",
    "  if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "  if len(nouts)>0:\n",
    "    threshold = nouts[0][3]\n",
    "  else:\n",
    "    threshold = pouts[-1][3]\n",
    "  \n",
    "  for item in [(pouts, 'positive(false_negative).png'), (nouts, 'negative(false_positive).png')]:\n",
    "    cols = 4\n",
    "    rows = 8000\n",
    "    outs = item[0]\n",
    "    if len(outs)==0:\n",
    "      continue\n",
    "    #if len(outs)==9:\n",
    "    #  cols = 3\n",
    "    #  rows = 3\n",
    "\n",
    "    _rows = int(math.ceil(len(outs)/cols))\n",
    "    rows = min(rows, _rows)\n",
    "    hack = {}\n",
    "\n",
    "    if name.startswith('cfp') and item[1].startswith('pos'):\n",
    "      hack = {0:'manual/238_13.jpg.jpg', 6:'manual/088_14.jpg.jpg', 10:'manual/470_14.jpg.jpg', 25:'manual/238_13.jpg.jpg', 28:'manual/143_11.jpg.jpg'}\n",
    "\n",
    "    filename = item[1]\n",
    "    if len(name)>0:\n",
    "      filename = name+\"_\"+filename\n",
    "    filename = os.path.join(out_dir, filename)\n",
    "    img = np.zeros( (image_shape[0]*rows+20, image_shape[1]*cols+(cols-1)*gap, 3), dtype=np.uint8 )\n",
    "    img[:,:,:] = 255\n",
    "    text_color = (0,0,153)\n",
    "    text_color = (255,178,102)\n",
    "    text_color = (153,255,51)\n",
    "    for outi, out in enumerate(outs):\n",
    "      row = outi//cols\n",
    "      col = outi%cols\n",
    "      if row==rows:\n",
    "        break\n",
    "      imga = out[0].copy()\n",
    "      imgb = out[1].copy()\n",
    "      if outi in hack:\n",
    "        idx = out[4]\n",
    "        print('noise idx',idx)\n",
    "        aa = hack[outi]\n",
    "        imgb = cv2.imread(aa)\n",
    "        #if aa==1:\n",
    "        #  imgb = cv2.transpose(imgb)\n",
    "        #  imgb = cv2.flip(imgb, 1)\n",
    "        #elif aa==3:\n",
    "        #  imgb = cv2.transpose(imgb)\n",
    "        #  imgb = cv2.flip(imgb, 0)\n",
    "        #else:\n",
    "        #  for ii in range(2):\n",
    "        #    imgb = cv2.transpose(imgb)\n",
    "        #    imgb = cv2.flip(imgb, 1)\n",
    "      dist = out[2]\n",
    "      _img = np.concatenate( (imga, imgb), axis=1 )\n",
    "      k = \"%.3f\"%dist\n",
    "      #print(k)\n",
    "      font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "      cv2.putText(_img,k,(80,image_shape[0]//2+7), font, 0.6, text_color, 2)\n",
    "      #_filename = filename+\"_%d.png\"%outi\n",
    "      #cv2.imwrite(_filename, _img)\n",
    "      img[row*image_shape[0]:(row+1)*image_shape[0], (col*image_shape[1]+gap*col):((col+1)*image_shape[1]+gap*col),:] = _img\n",
    "    #threshold = outs[0][3]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    k = \"threshold: %.3f\"%threshold\n",
    "    cv2.putText(img,k,(img.shape[1]//2-70,img.shape[0]-5), font, 0.6, text_color, 2)\n",
    "    cv2.imwrite(filename, img)\n",
    "\n",
    "def dumpR(data_set, mx_model, batch_size, name='', data_extra = None, label_shape = None):\n",
    "  print('dump verification embedding..')\n",
    "  data_list = data_set[0]\n",
    "  issame_list = data_set[1]\n",
    "  model = mx_model\n",
    "  embeddings_list = []\n",
    "  if data_extra is not None:\n",
    "    _data_extra = nd.array(data_extra)\n",
    "  time_consumed = 0.0\n",
    "  if label_shape is None:\n",
    "    _label = nd.ones( (batch_size,) )\n",
    "  else:\n",
    "    _label = nd.ones( label_shape )\n",
    "  for i in range( len(data_list) ):\n",
    "    data = data_list[i]\n",
    "    embeddings = None\n",
    "    ba = 0\n",
    "    while ba<data.shape[0]:\n",
    "      bb = min(ba+batch_size, data.shape[0])\n",
    "      count = bb-ba\n",
    "      _data = nd.slice_axis(data, axis=0, begin=bb-batch_size, end=bb)\n",
    "      #print(_data.shape, _label.shape)\n",
    "      time0 = datetime.datetime.now()\n",
    "      if data_extra is None:\n",
    "        db = mx.io.DataBatch(data=(_data,), label=(_label,))\n",
    "      else:\n",
    "        db = mx.io.DataBatch(data=(_data,_data_extra), label=(_label,))\n",
    "      model.forward(db, is_train=False)\n",
    "      net_out = model.get_outputs()\n",
    "      _embeddings = net_out[0].asnumpy()\n",
    "      time_now = datetime.datetime.now()\n",
    "      diff = time_now - time0\n",
    "      time_consumed+=diff.total_seconds()\n",
    "      if embeddings is None:\n",
    "        embeddings = np.zeros( (data.shape[0], _embeddings.shape[1]) )\n",
    "      embeddings[ba:bb,:] = _embeddings[(batch_size-count):,:]\n",
    "      ba = bb\n",
    "    embeddings_list.append(embeddings)\n",
    "  embeddings = embeddings_list[0] + embeddings_list[1]\n",
    "  embeddings = sklearn.preprocessing.normalize(embeddings)\n",
    "  actual_issame = np.asarray(issame_list)\n",
    "  outname = os.path.join('temp.bin')\n",
    "  with open(outname, 'wb') as f:\n",
    "    pickle.dump((embeddings, issame_list), f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  parser = argparse.ArgumentParser(description='do verification')\n",
    "  # general\n",
    "  parser.add_argument('--data-dir', default='', help='')\n",
    "  parser.add_argument('--model', default='./models/model', help='path to load model.')\n",
    "  parser.add_argument('--target', default='lfw,cfp_ff,cfp_fp,agedb_30', help='test targets.')\n",
    "  parser.add_argument('--gpu', default=1, type=int, help='gpu id')\n",
    "  parser.add_argument('--batch-size', default=32, type=int, help='')\n",
    "  parser.add_argument('--max', default='', type=str, help='')\n",
    "  parser.add_argument('--mode', default=0, type=int, help='')\n",
    "  parser.add_argument('--nfolds', default=10, type=int, help='')\n",
    "  args = parser.parse_args(args=[])\n",
    "  #sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'common'))\n",
    "  #import face_image\n",
    "  #prop = face_image.load_property(args.data_dir)\n",
    "  #image_size = prop.image_size\n",
    "  image_size = [112,112]\n",
    "  print('image_size', image_size)\n",
    "  ctx = mx.gpu(args.gpu)\n",
    "  nets = []\n",
    "  vec = args.model.split(',')\n",
    "  prefix = args.model.split(',')[0]\n",
    "  epochs = []\n",
    "  if len(vec)==1:\n",
    "    pdir = os.path.dirname(prefix)\n",
    "    for fname in os.listdir(pdir):\n",
    "      if not fname.endswith('.params'):\n",
    "        continue\n",
    "      _file = os.path.join(pdir, fname)\n",
    "      if _file.startswith(prefix):\n",
    "        epoch = int(fname.split('.')[0].split('-')[1])\n",
    "        epochs.append(epoch)\n",
    "    epochs = sorted(epochs, reverse=True)\n",
    "    if len(args.max)>0:\n",
    "      _max = [int(x) for x in args.max.split(',')]\n",
    "      assert len(_max)==2\n",
    "      if len(epochs)>_max[1]:\n",
    "        epochs = epochs[_max[0]:_max[1]]\n",
    "\n",
    "  else:\n",
    "    epochs = [int(x) for x in vec[1].split('|')]\n",
    "  print('model number', len(epochs))\n",
    "  time0 = datetime.datetime.now()\n",
    "  for epoch in epochs:\n",
    "    print('loading',prefix, epoch)\n",
    "    sym, arg_params, aux_params = mx.model.load_checkpoint(prefix, epoch)\n",
    "    #arg_params, aux_params = ch_dev(arg_params, aux_params, ctx)\n",
    "    all_layers = sym.get_internals()\n",
    "    sym = all_layers['fc1_output']\n",
    "    model = mx.mod.Module(symbol=sym, context=ctx, label_names = None)\n",
    "    #model.bind(data_shapes=[('data', (args.batch_size, 3, image_size[0], image_size[1]))], label_shapes=[('softmax_label', (args.batch_size,))])\n",
    "    model.bind(data_shapes=[('data', (args.batch_size, 3, image_size[0], image_size[1]))])\n",
    "    model.set_params(arg_params, aux_params)\n",
    "    nets.append(model)\n",
    "  time_now = datetime.datetime.now()\n",
    "  diff = time_now - time0\n",
    "  print('model loading time', diff.total_seconds())\n",
    "\n",
    "  ver_list = []\n",
    "  ver_name_list = []\n",
    "\n",
    "  print(args.data_dir)\n",
    "  print(name)\n",
    "\n",
    "  for name in args.target.split(','):\n",
    "    path = os.path.join(args.data_dir,name+\".bin\")\n",
    "    if os.path.exists(path):\n",
    "      print('loading.. ', name)\n",
    "      data_set = load_bin(path, image_size)\n",
    "      ver_list.append(data_set)\n",
    "      ver_name_list.append(name)\n",
    "\n",
    "  if args.mode==0:\n",
    "    for i in range(len(ver_list)):\n",
    "      results = []\n",
    "      for model in nets:\n",
    "        acc1, std1, acc2, std2, xnorm, embeddings_list = test(ver_list[i], model, args.batch_size, args.nfolds)\n",
    "        print('[%s]XNorm: %f' % (ver_name_list[i], xnorm))\n",
    "        print('[%s]Accuracy: %1.5f+-%1.5f' % (ver_name_list[i], acc1, std1))\n",
    "        print('[%s]Accuracy-Flip: %1.5f+-%1.5f' % (ver_name_list[i], acc2, std2))\n",
    "        results.append(acc2)\n",
    "      print('Max of [%s] is %1.5f' % (ver_name_list[i], np.max(results)))\n",
    "  elif args.mode==1:\n",
    "    model = nets[0]\n",
    "    test_badcase(ver_list[0], model, args.batch_size, args.target)\n",
    "  else:\n",
    "    model = nets[0]\n",
    "    dumpR(ver_list[0], model, args.batch_size, args.target)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-7cf9ea8262dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFaceModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../users/biden.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI_Project/MaskTheFace/deploy/face_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'!!!!!!!!!!!!!!!!!!!1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mga_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI_Project/MaskTheFace/deploy/face_model.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(ctx, image_size, model_str, layer)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'11234124'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0m_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import deploy.face_model\n",
    "import argparse\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "parser = argparse.ArgumentParser(description='face model test')\n",
    "# general\n",
    "parser.add_argument('--image_size', default='112,112', help='')\n",
    "parser.add_argument('--model', default='./models/model-0000.params', help='./models/')\n",
    "parser.add_argument('--ga-model', default='', help='path to load model.')\n",
    "parser.add_argument('--gpu', default=1, type=int, help='gpu id')\n",
    "parser.add_argument('--det', default=0, type=int, help='mtcnn option, 1 means using R+O, 0 means detect from begining')\n",
    "parser.add_argument('--flip', default=0, type=int, help='whether do lr flip aug')\n",
    "parser.add_argument('--threshold', default=1.24, type=float, help='ver dist threshold')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "model = deploy.face_model.FaceModel(args)\n",
    "img = cv2.imread('../users/biden.jpg')\n",
    "img = model.get_input(img)\n",
    "#f1 = model.get_feature(img)\n",
    "#print(f1[0:10])\n",
    "gender, age = model.get_ga(img)\n",
    "print(gender)\n",
    "print(age)\n",
    "sys.exit(0)\n",
    "img = cv2.imread('../users/biden_N95.jpg')\n",
    "f2 = model.get_feature(img)\n",
    "dist = np.sum(np.square(f1-f2))\n",
    "print(dist)\n",
    "sim = np.dot(f1, f2.T)\n",
    "print(sim)\n",
    "#diff = np.subtract(source_feature, target_feature)\n",
    "#dist = np.sum(np.square(diff),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
